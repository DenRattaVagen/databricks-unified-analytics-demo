# Unified Analytics on Apache Spark (Databricks Demo)

This repository demonstrates how to build a unified analytics pipeline using Databricks on top of Apache Spark.

ğŸ”§ **Features**:
- Ingest batch data using PySpark
- Transform and persist data using Delta Lake
- Query results with SQL
- Log MLflow metrics in the same pipeline

## ğŸ“ Contents
- `notebooks/`: Unified pipeline using PySpark, SQL, and MLflow
- `data/`: Sample dataset (`users.json`)
- `article/`: Accompanying blog post (Markdown)
- `images/`: Visuals (roadmap, diagrams)

## ğŸ“˜ Blog Post
Read the full article: [Deep Dive: Unified Analytics on Apache Spark](#)

## ğŸ’¡ How to Use
1. Upload the notebook to Databricks
2. Load `users.json` into `/mnt/raw/users.json`
3. Run the notebook and explore

## ğŸ—ï¸ Technologies
- Apache Spark
- Delta Lake
- MLflow
- Databricks Platform
